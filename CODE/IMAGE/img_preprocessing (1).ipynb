{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUY4X_HXuzpw"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# STAGE 1 ‚Äì INSTALLS\n",
        "# ============================================================\n",
        "!pip install -q torch torchvision scikit-learn opencv-python-headless\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 1) IMPORTS + SEED\n",
        "# ============================================================\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "print(\"‚úÖ Seed set to 42\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9nJsTqjDcyG",
        "outputId": "698fceef-e1d6-4a35-dd1b-7d88a61052d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Seed set to 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 2) PATHS (Drive + Dataset + PREPROC ROOT)\n",
        "# ============================================================\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BASE_PATH = '/content/drive/MyDrive/MultiBanFake/Dataset'\n",
        "TRAIN_DIR = os.path.join(BASE_PATH, 'Train')\n",
        "VAL_DIR   = os.path.join(BASE_PATH, 'Validation')\n",
        "TEST_DIR  = os.path.join(BASE_PATH, 'Test')\n",
        "\n",
        "print(\"Train:\", TRAIN_DIR)\n",
        "print(\"Val  :\", VAL_DIR)\n",
        "print(\"Test :\", TEST_DIR)\n",
        "\n",
        "PREPROC_ROOT = \"/content/drive/MyDrive/MultiBanFake/preprocessed\"\n",
        "os.makedirs(PREPROC_ROOT, exist_ok=True)\n",
        "print(\"PREPROC_ROOT:\", PREPROC_ROOT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hDF5mw0DoUV",
        "outputId": "81279c21-811e-489e-9f7d-93ff508a7aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Train: /content/drive/MyDrive/MultiBanFake/Dataset/Train\n",
            "Val  : /content/drive/MyDrive/MultiBanFake/Dataset/Validation\n",
            "Test : /content/drive/MyDrive/MultiBanFake/Dataset/Test\n",
            "PREPROC_ROOT: /content/drive/MyDrive/MultiBanFake/preprocessed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 3) BLUR ANALYSIS ON TRAIN (percentile-based threshold)\n",
        "# ============================================================\n",
        "def laplacian_var(pil_img):\n",
        "    g = np.array(pil_img.convert(\"L\"))\n",
        "    return cv2.Laplacian(g, cv2.CV_64F).var()\n",
        "\n",
        "def compute_blur_values(root):\n",
        "    ds = ImageFolder(root=root)\n",
        "    vals = []\n",
        "    for path, _ in ds.samples:\n",
        "        try:\n",
        "            img = Image.open(path).convert(\"RGB\")\n",
        "        except:\n",
        "            continue\n",
        "        vals.append(laplacian_var(img))\n",
        "    vals = np.array(vals)\n",
        "    print(\"Total images:\", len(vals))\n",
        "    print(\"min:\", vals.min(), \"max:\", vals.max())\n",
        "    for p in [1, 2, 5, 10]:\n",
        "        print(f\"p{p}:\", np.percentile(vals, p))\n",
        "    return vals\n",
        "\n",
        "blur_vals_train = compute_blur_values(TRAIN_DIR)\n",
        "BLUR_THRESH_TRAIN = float(np.percentile(blur_vals_train, 1))  # bottom 1% extreme blur\n",
        "print(\"üëâ Using BLUR_THRESH_TRAIN =\", BLUR_THRESH_TRAIN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STDL88vJDqo_",
        "outputId": "22b130d6-2efd-41e7-e879-1dcb8ceb3dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 7680\n",
            "min: 1.2552251173109121 max: 41068.54664945558\n",
            "p1: 32.72085731788798\n",
            "p2: 48.9287317643156\n",
            "p5: 79.87211807113705\n",
            "p10: 122.56347494283445\n",
            "üëâ Using BLUR_THRESH_TRAIN = 32.72085731788798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 4) PREPROCESS SPLITS -> SAVE AS NPZ (Train/Val/Test)\n",
        "# ============================================================\n",
        "IMG_SIZE = 224  # sob model er jonno common size\n",
        "\n",
        "def preprocess_split(root, apply_blur_filter=False, blur_thresh=None):\n",
        "    ds = ImageFolder(root=root)\n",
        "    resize_tf = transforms.Resize((IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    kept = 0\n",
        "    skipped = 0\n",
        "\n",
        "    print(f\"\\nüîç Preprocessing: {root}\")\n",
        "    for path, lbl in ds.samples:\n",
        "        try:\n",
        "            img = Image.open(path).convert(\"RGB\")\n",
        "        except Exception as e:\n",
        "            print(\"‚ö†Ô∏è Failed to open:\", path, \"|\", e)\n",
        "            continue\n",
        "\n",
        "        # ‚úÖ blur handle (agey je chilo)\n",
        "        if apply_blur_filter and (blur_thresh is not None):\n",
        "            v = laplacian_var(img)\n",
        "            if v < blur_thresh:\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "        img = resize_tf(img)\n",
        "        img = np.array(img, dtype=np.uint8)  # HWC, uint8\n",
        "\n",
        "        images.append(img)\n",
        "        labels.append(lbl)\n",
        "        kept += 1\n",
        "\n",
        "    images = np.stack(images, axis=0)   # [N, H, W, C]\n",
        "    labels = np.array(labels, dtype=np.int64)\n",
        "\n",
        "    print(f\"{root}: kept={kept}, skipped_extreme_blur={skipped}\")\n",
        "    return images, labels, ds.classes\n",
        "\n",
        "# üîπ Train: extreme blur drop\n",
        "train_imgs, train_labels, classes = preprocess_split(\n",
        "    TRAIN_DIR, apply_blur_filter=True, blur_thresh=BLUR_THRESH_TRAIN\n",
        ")\n",
        "\n",
        "# üîπ Val/Test: usually blur filter off (but chao to on korte paro)\n",
        "val_imgs, val_labels, _ = preprocess_split(\n",
        "    VAL_DIR, apply_blur_filter=False, blur_thresh=None\n",
        ")\n",
        "test_imgs, test_labels, _ = preprocess_split(\n",
        "    TEST_DIR, apply_blur_filter=False, blur_thresh=None\n",
        ")\n",
        "\n",
        "print(\"\\nTrain shape:\", train_imgs.shape, train_labels.shape)\n",
        "print(\"Val   shape:\", val_imgs.shape, val_labels.shape)\n",
        "print(\"Test  shape:\", test_imgs.shape, test_labels.shape)\n",
        "\n",
        "# ‚úÖ Direct drive e NPZ save (ekbar run = sob model use)\n",
        "np.savez_compressed(\n",
        "    os.path.join(PREPROC_ROOT, \"train_npz.npz\"),\n",
        "    images=train_imgs, labels=train_labels\n",
        ")\n",
        "np.savez_compressed(\n",
        "    os.path.join(PREPROC_ROOT, \"val_npz.npz\"),\n",
        "    images=val_imgs, labels=val_labels\n",
        ")\n",
        "np.savez_compressed(\n",
        "    os.path.join(PREPROC_ROOT, \"test_npz.npz\"),\n",
        "    images=test_imgs, labels=test_labels\n",
        ")\n",
        "\n",
        "with open(os.path.join(PREPROC_ROOT, \"classes.json\"), \"w\") as f:\n",
        "    json.dump(classes, f, indent=4)\n",
        "\n",
        "print(\"\\n‚úÖ Saved preprocessed numpy datasets to\", PREPROC_ROOT)\n",
        "print(\"   - train_npz.npz\")\n",
        "print(\"   - val_npz.npz\")\n",
        "print(\"   - test_npz.npz\")\n",
        "print(\"   - classes.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcSvTmyaDsL8",
        "outputId": "743da005-2711-41b0-a00d-f48acd93cda2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Preprocessing: /content/drive/MyDrive/MultiBanFake/Dataset/Train\n",
            "/content/drive/MyDrive/MultiBanFake/Dataset/Train: kept=7603, skipped_extreme_blur=77\n",
            "\n",
            "üîç Preprocessing: /content/drive/MyDrive/MultiBanFake/Dataset/Validation\n",
            "/content/drive/MyDrive/MultiBanFake/Dataset/Validation: kept=957, skipped_extreme_blur=0\n",
            "\n",
            "üîç Preprocessing: /content/drive/MyDrive/MultiBanFake/Dataset/Test\n",
            "/content/drive/MyDrive/MultiBanFake/Dataset/Test: kept=957, skipped_extreme_blur=0\n",
            "\n",
            "Train shape: (7603, 224, 224, 3) (7603,)\n",
            "Val   shape: (957, 224, 224, 3) (957,)\n",
            "Test  shape: (957, 224, 224, 3) (957,)\n",
            "\n",
            "‚úÖ Saved preprocessed numpy datasets to /content/drive/MyDrive/MultiBanFake/preprocessed\n",
            "   - train_npz.npz\n",
            "   - val_npz.npz\n",
            "   - test_npz.npz\n",
            "   - classes.json\n"
          ]
        }
      ]
    }
  ]
}