{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-5MBgx0aZbu",
        "outputId": "51e17d09-9853-42f0-f436-4ae14510533a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# âœ… 1. Install required libraries\n",
        "!pip install -q torch torchvision torchaudio pandas scikit-learn nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dab3EztobvdE",
        "outputId": "3adc970a-a7bb-467e-c6e0-01e0d825058b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 3. Imports\n",
        "import os\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "9xJal0g6agUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 4. Hyperparameters and Save Path\n",
        "MAX_LEN = 200\n",
        "BATCH_SIZE = 32\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 128\n",
        "NUM_CLASSES = 2\n",
        "EPOCHS = 5\n",
        "LR = 1e-3\n",
        "SAVE_DIR = \"/content/drive/MyDrive/MultiBanFake/LSTM_Results\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "gAw6CUy0ah30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 5. Load and Prepare Data\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/MultiBanFake/Dataset/text/Train.csv\")\n",
        "val_df = pd.read_csv(\"/content/drive/MyDrive/MultiBanFake/Dataset/text/Validation.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/MultiBanFake/Dataset/text/Test.csv\")\n",
        "\n",
        "for df in [train_df, val_df, test_df]:\n",
        "    df[\"headline\"] = df[\"headline\"].fillna(\"\").astype(str)\n",
        "    df[\"description\"] = df[\"description\"].fillna(\"\").astype(str)\n",
        "    df[\"text\"] = df[\"headline\"].str.strip() + \" \" + df[\"description\"].str.strip()\n"
      ],
      "metadata": {
        "id": "7U2itN4Xaj7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 6. Build Vocabulary\n",
        "def simple_tokenize(text):\n",
        "    return re.findall(r\"\\b\\w+\\b\", text.lower())\n",
        "\n",
        "from collections import Counter\n",
        "all_texts = train_df[\"text\"].tolist()\n",
        "tokenized_texts = [simple_tokenize(t) for t in all_texts]\n",
        "word_counts = Counter(token for sent in tokenized_texts for token in sent)\n",
        "\n",
        "vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "for word, freq in word_counts.items():\n",
        "    if freq >= 2:\n",
        "        vocab[word] = len(vocab)"
      ],
      "metadata": {
        "id": "a3tlKl60aoDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 7. Encode text\n",
        "def encode(text, max_len=MAX_LEN):\n",
        "    tokens = simple_tokenize(text)\n",
        "    ids = [vocab.get(token, vocab[\"<UNK>\"]) for token in tokens]\n",
        "    if len(ids) < max_len:\n",
        "        ids += [vocab[\"<PAD>\"]] * (max_len - len(ids))\n",
        "    else:\n",
        "        ids = ids[:max_len]\n",
        "    return torch.tensor(ids)"
      ],
      "metadata": {
        "id": "zUc68Dopa8XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 8. Custom Dataset\n",
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.texts = df[\"text\"].tolist()\n",
        "        self.labels = df[\"label\"].astype(int).tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input\": encode(self.texts[idx]),\n",
        "            \"label\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "train_dataset = NewsDataset(train_df)\n",
        "val_dataset = NewsDataset(val_df)\n",
        "test_dataset = NewsDataset(test_df)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "LsPqxRhka_bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 9. LSTM Model\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        _, (hn, _) = self.lstm(x)\n",
        "        out = self.fc(hn[-1])\n",
        "        return out\n",
        "\n",
        "model = LSTMClassifier(len(vocab), EMBEDDING_DIM, HIDDEN_DIM, NUM_CLASSES)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zJSEQO7bCHs",
        "outputId": "4ee27ae5-4b8f-487a-e3a6-0516b0977770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMClassifier(\n",
              "  (embedding): Embedding(5174, 128, padding_idx=0)\n",
              "  (lstm): LSTM(128, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 10. Train Loop\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        inputs = batch[\"input\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"âœ… Epoch {epoch+1}/{EPOCHS} - Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3DAmM1vbEVM",
        "outputId": "23d05a98-0a0d-41c7-d909-631af3d451a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Epoch 1/5 - Loss: 167.1129\n",
            "âœ… Epoch 2/5 - Loss: 164.9368\n",
            "âœ… Epoch 3/5 - Loss: 160.6281\n",
            "âœ… Epoch 4/5 - Loss: 147.8611\n",
            "âœ… Epoch 5/5 - Loss: 124.1390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 11. Save Model\n",
        "model_path = os.path.join(SAVE_DIR, \"lstm_model.pt\")\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"âœ… Model saved to: {model_path}\")\n",
        "\n",
        "# âœ… 12. Evaluation\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs = batch[\"input\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "        outputs = model(inputs)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhHo0SUIbG2K",
        "outputId": "1cab9393-98e7-443a-f8d9-237a5df98f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model saved to: /content/drive/MyDrive/MultiBanFake/LSTM_Results/lstm_model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 13. Save Results\n",
        "from datetime import datetime\n",
        "\n",
        "acc = accuracy_score(all_labels, all_preds)\n",
        "report = classification_report(all_labels, all_preds, target_names=[\"Non-Fake\", \"Fake\"])\n",
        "\n",
        "# Save predictions\n",
        "results_df = pd.DataFrame({\n",
        "    \"true_label\": all_labels,\n",
        "    \"predicted_label\": all_preds\n",
        "})\n",
        "results_csv = os.path.join(SAVE_DIR, \"test_predictions.csv\")\n",
        "results_df.to_csv(results_csv, index=False)\n",
        "\n",
        "# Save report\n",
        "report_txt = os.path.join(SAVE_DIR, \"classification_report.txt\")\n",
        "with open(report_txt, \"w\") as f:\n",
        "    f.write(f\"Test Accuracy: {acc:.4f}\\n\\n\")\n",
        "    f.write(report)\n",
        "\n",
        "print(f\"\\nğŸ”¹ Test Accuracy: {acc:.4f}\")\n",
        "print(\"\\nğŸ” Classification Report:\")\n",
        "print(report)\n",
        "print(f\"\\nâœ… Predictions saved to: {results_csv}\")\n",
        "print(f\"âœ… Report saved to: {report_txt}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfyWWQkBeSB-",
        "outputId": "92d9db22-f6cb-4244-cc33-7fba01cbcafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”¹ Test Accuracy: 0.5365\n",
            "\n",
            "ğŸ” Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Non-Fake       0.55      0.42      0.47       480\n",
            "        Fake       0.53      0.65      0.59       480\n",
            "\n",
            "    accuracy                           0.54       960\n",
            "   macro avg       0.54      0.54      0.53       960\n",
            "weighted avg       0.54      0.54      0.53       960\n",
            "\n",
            "\n",
            "âœ… Predictions saved to: /content/drive/MyDrive/MultiBanFake/LSTM_Results/test_predictions.csv\n",
            "âœ… Report saved to: /content/drive/MyDrive/MultiBanFake/LSTM_Results/classification_report.txt\n"
          ]
        }
      ]
    }
  ]
}